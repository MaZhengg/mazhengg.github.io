<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ESKF的四元数运动学方程推导方法]]></title>
    <url>%2F2023%2F12%2F17%2FESKF%E7%9A%84%E5%9B%9B%E5%85%83%E6%95%B0%E8%BF%90%E5%8A%A8%E5%AD%A6%E6%96%B9%E7%A8%8B%E6%8E%A8%E5%AF%BC%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在SAD的书籍中已经有了ESKF的李群和李代数运动学方程的推导方法，本文主要是利用四元数来推导ESKF的运动学方程。 连续时间运动学方程 Magnitude True Nominal Error Composition Measured Noise Full state $x_{t}$ $x$ $\delta x$ $x_{t}=x\otimes\delta x$ Position $p_{t}$ $p$ $\delta p$ $p_{t}=p+\delta p$ Velocity $v_{t}$ $v$ $\delta v$ $v_{t}=v+\delta v$ Quaternion $q_{t}$ $q$ $\delta q$ $q_{t}=q\delta q$ Rotation matrix $R_{t}$ $R$ $\delta R$ $R_{t}=R\delta R$ Angles vector $\delta\theta$ $\delta q=Exp(\frac{\delta\theta}{2})$$\delta R=Exp(\delta\theta)$ Accelerometer bias $b_{at}$ $b_{a}$ $\delta b_{a}$ $b_{at}=b_{a}+\delta b_{a}$ $\eta_{ba}$ Gyrometer bias $b_{gt}$ $b_{g}$ $\delta b_{g}$ $b_{gt}=b_{g}+\delta b_{g}$ $\eta_{bg}$ Gravity vector $g_{t}$ $g$ $\delta g$ $g_{t}=g+\delta g$ Acceleration $a_{t}$ $a$ $\tilde{a}$ $\eta_{a}$ Angular rate $\omega_{t}$ $\omega$ $\tilde{\omega}$ $\eta_{g}$ IMU测量方程中的噪声模型记陀螺仪和加速度计的测量噪声分别为$\eta_{g},\eta_{a}$，同时记零偏为$b_{g},b_{a}$，下标$g$表示陀螺仪，下标$a$表示加速度计。那么这几个参数在测量方程中体现为$$\begin{eqnarray}\tilde{a} &amp; = &amp; R^{T}(a_{t}-g)+b_{a}+\eta_{a}\tag{1.18}\\tilde{\omega} &amp; = &amp; \omega_{t}+b_{g}+\eta_{g}\tag{1.19}\end{eqnarray}$$一个普通的零偏$b$的随机游走过程可以建模为$$\begin{equation}\dot{b}(t)=\eta_{b}(t)\tag{1.20}\end{equation}$$其中$\eta_{b}(t)$也是一个高斯过程。于是，$b_{a}$和$b_{g}$的随机游走可以建模为$$\begin{eqnarray}\dot{b}{a}(t) &amp; = &amp; \eta{ba}(t)\sim\mathcal{GP}(0,Cov(b_{a})\delta(t-t’))\tag{1.21}\\dot{b}{g}(t) &amp; = &amp; \eta{bg}(t)\sim\mathcal{GP}(0,Cov(b_{g})\delta(t-t’))\tag{1.22}\end{eqnarray}$$ 真值运动学方程设ESKF的真值状态为$x_{t}=[p_{t},v_{t},q_{t},b_{at},b_{gt},g_{t}]^{T}$，下标$t$表示true，即真值状态。这个状态随时间改变，可以记作$x_{t}(t)$。在连续时间上，记IMU读数为$\tilde{\omega},\tilde{a}$，那么可以写出真值运动学方程式$$$$$$\begin{eqnarray}\dot{p}{t} &amp; = &amp; v{t}\tag{1.23}\\dot{v}{t} &amp; = &amp; a{t}\tag{1.24}\\dot{q}{t} &amp; = &amp; \frac{1}{2}q{t}\otimes\omega_{t}\tag{1.25}\\dot{b}{gt} &amp; = &amp; \eta{bg}\tag{1.26}\\dot{b}{at} &amp; = &amp; \eta{ba}\tag{1.27}\\dot{g}{t} &amp; = &amp; 0\tag{1.28}\end{eqnarray}$$根据公式$(1.18)$和$(1.19)$，真值可以表示为$$\begin{eqnarray}a{t} &amp; = &amp; R_{t}(\tilde{a}-b_{at}-\eta_{a})+g_{t}\tag{1.29}\\omega_{t} &amp; = &amp; \tilde{\omega}-b_{gt}-\eta_{g}\tag{1.30}\end{eqnarray}$$ 其中，$R_{t}=R\delta R= RExp(\delta\theta)$，将上式带入真值运动学方程可以改写为$$\begin{eqnarray}\dot{p}{t} &amp; = &amp; v{t}\tag{1.31}\\dot{v}{t} &amp; = &amp; R{t}(\tilde{a}-b_{at}-\eta_{a})+g_{t}\tag{1.32}\\dot{q}{t} &amp; = &amp; \frac{1}{2}q{t}\otimes(\tilde{\omega}-b_{gt}-\eta_{g})\tag{1.33}\\dot{b}{gt} &amp; = &amp; \eta{bg}\tag{1.34}\\dot{b}{at} &amp; = &amp; \eta{ba}\tag{1.35}\\dot{g}_{t} &amp; = &amp; 0\tag{1.36}\end{eqnarray}$$ 误差状态变量根据上面的表格，定义误差状态变量：$$\begin{eqnarray}p_{t} &amp; = &amp; p+\delta p\tag{1.37}\v_{t} &amp; = &amp; v+\delta v\tag{1.38}\q_{t} &amp; = &amp; q\delta q\tag{1.39}\b_{gt} &amp; = &amp; b_{g}+\delta b_{g}\tag{1.40}\b_{at} &amp; = &amp; b_{a}+\delta b_{a}\tag{1.41}\g_{t} &amp; = &amp; g+\delta g\tag{1.42}\end{eqnarray}$$ 不带下标的就是名义状态变量。名义状态变量的运动学方程与真值相同，只是不必考虑噪声（因为噪声在误差状态方程中考虑了）。名义状态变量的运动学方程可以写为$$\begin{eqnarray}\dot{p} &amp; = &amp; v\tag{1.43}\\dot{v} &amp; = &amp; R(\tilde{a}-b_{a})+g\tag{1.44}\\dot{q} &amp; = &amp; \frac{1}{2}q\otimes(\tilde{\omega}-b_{g})\tag{1.45}\\dot{b}{g} &amp; = &amp; 0\tag{1.46}\\dot{b}{a} &amp; = &amp; 0\tag{1.47}\\dot{g} &amp; = &amp; 0\tag{1.48}\end{eqnarray}$$ 在误差状态的公式$(1.37)(1.40)(1.41)(1.42)$中，在等式两侧分别对时间求导，很容易得到对应的时间导数表达式：$$\begin{eqnarray}\dot{\delta p} &amp; = &amp; \delta v\tag{1.49}\\dot{\delta v} &amp; = &amp; -R(\tilde{a}-b_{a})^{\wedge}\delta\theta-R\delta b_{a}-\eta_{a}+\delta g\tag{1.50}\\dot{\delta\theta} &amp; = &amp; -(\tilde{\omega}-b_{g})^{\wedge}\delta\theta-\delta b_{g}-\eta_{g}\tag{1.51}\\dot{\delta b_{g}} &amp; = &amp; \eta_{g}\tag{1.52}\\dot{\delta b_{a}} &amp; = &amp; \eta_{a}\tag{1.53}\\dot{\delta g} &amp; = &amp; 0\tag{1.54}\end{eqnarray}$$ 其中，公式$(1.50)$和$(1.51)$分别是速度和旋转误差，需要针对$(1.32)$和$(1.33)$这两个非线性公式做一些复杂处理，得到一个线性方程，下面给出单独的推导。 误差状态的速度项我们希望得到$\dot{\delta v}$这个关于速度误差的方程，考虑公式$(1.38)$的误差形式。对两侧求时间导数，就可以得到$\dot{\delta v}$的表达式。 公式$(1.38)$的左侧为：$$\begin{align}\dot{v}{t} &amp; =R{t}(\tilde{a}-b_{at}-\eta_{a})+g_{t}\nonumber \ &amp; =RExp(\delta\theta)(\tilde{a}-b_{a}-\delta b_{a}-\eta_{a})+g+\delta g\nonumber \ &amp; \approx R(I+\delta\theta^{\wedge})(\tilde{a}-b_{a}-\delta b_{a}-\eta_{a})+g+\delta g\ &amp; =R(\tilde{a}-b_{a})+R(-\delta b_{a}-\eta_{a})+R\delta\theta^{\wedge}(\tilde{a}-b_{a})+R\delta\theta^{\wedge}(-\delta b_{a}-\eta_{a})+g+\delta g\nonumber\end{align}\tag{1.55}$$ 其中上式分别将真值$b_{at}$和$g_{t}$展开为名义状态变量和误差状态变量，“$\approx$”来自于$Exp(\delta\theta)$的展开，省略了二阶小量。 公式$(1.38)$的右侧为：$$\begin{align}\dot{v}+\dot{\delta v} &amp; =R(\tilde{a}-b_{a})+g+\dot{\delta v}\tag{1.56}\end{align}$$ 因为公式$(1.38)$的两侧相等，可以得到$$\begin{align}R(\tilde{a}-b_{a})+g+\dot{\delta v} &amp; =R(\tilde{a}-b_{a})+R(-\delta b_{a}-\eta_{a}) \ &amp; +R\delta\theta^{\wedge}(\tilde{a}-b_{a})+R\delta\theta^{\wedge}(-\delta b_{a}-\eta_{a})+g+\delta g\end{align}\tag{1.57}$$将公式两侧的$R(\tilde{a}-b_{a})+g$消去后，可以得到$$\begin{align}\dot{\delta v} &amp; =R(-\delta b_{a}-\eta_{a})+R\delta\theta^{\wedge}(\tilde{a}-b_{a})+R\delta\theta^{\wedge}(-\delta b_{a}-\eta_{a})+\delta g \ &amp; =-R\delta b_{a}-R\eta_{a}+R\delta\theta^{\wedge}\tilde{a}-R\delta\theta^{\wedge}b_{a}-R\delta\theta^{\wedge}\delta b_{a}-R\delta\theta^{\wedge}\eta_{a}+\delta g \ &amp; \approx-R\delta b_{a}-R\eta_{a}+R\delta\theta^{\wedge}\tilde{a}-R\delta\theta^{\wedge}b_{a}+\delta g\ &amp; =-R\delta b_{a}-R\eta_{a}-R\tilde{a}^{\wedge}\delta\theta+Rb_{a}^{\wedge}\delta\theta+\delta g \ &amp; =-R(\tilde{a}-b_{a})^{\wedge}\delta\theta-R\delta b_{a}-R\eta_{a}+\delta g\end{align}\tag{1.58}$$ 因此，$$\begin{equation}\boxed{\dot{\delta v}=-R(\tilde{a}-b_{a})^{\wedge}\delta\theta-R\delta b_{a}-R\eta_{a}+\delta g}\tag{1.59}\end{equation}$$ 这样就得到了$\delta v$的运动学模型。需要补充一句，式$(1.59)$中的$\eta_{a}$是一个零均值白噪声，也就是说$$\begin{equation}E[\eta_{a}]=0\qquad E[\eta_{a}\eta_{a}^{T}]=\sigma_{a}^{2}I\end{equation}\tag{1.60}$$ 它乘上任意旋转矩阵之后仍然是一个零均值白噪声，而且$R^{T}R=I$，容易证明其协方差矩阵也不变（Proof:$E[R\eta_{a}]=RE[\eta_{a}]=0$，$E[(R\eta_{a})(R\eta_{a})^{T}]=RE[\eta_{a}\eta_{a}^{T}]R^{T}=R\sigma_{a}^{2}IR^{T}=\sigma_{a}^{2}I$），因此，我们可以得到$$\begin{equation}\eta_{a}\leftarrow R\eta_{a}\end{equation}\tag{1.61}$$ 因此，公式$(1.59)$可以简化为公式$$\begin{equation}\boxed{\dot{\delta v}=-R(\tilde{a}-b_{a})^{\wedge}\delta\theta-R\delta b_{a}-\eta_{a}+\delta g}\end{equation}\tag{1.62}$$ 误差状态的旋转项针对四元数表示旋转，回顾之前的内容，指定$\mathbb{\phi}=\theta u$为表示绕轴$u$旋转$\theta$角度的旋转向量，那么指数映射可以通过欧拉公式展开，$$\begin{equation}q=Exp(\theta u)=e^{\frac{\theta u}{2}}=cos\frac{\theta}{2}+usin\frac{\theta}{2}=\left[\begin{array}{c}cos\frac{\theta}{2}\usin\frac{\theta}{2}\end{array}\right]\end{equation}\tag{1.63}$$ 如果$\theta$为小量，那么可以近似表示为$$\begin{equation}q=Exp(\theta u)=\left[\begin{array}{c}cos\frac{\theta}{2}\usin\frac{\theta}{2}\end{array}\right]\approx\left[\begin{array}{c}1\\frac{\theta}{2}\end{array}\right]\end{equation}\tag{1.64}$$根据之前定义的符号$$\begin{equation}q^{+}=\left[\begin{array}{cc}s &amp; -v^{T}\v &amp; sI+v^{\wedge}\end{array}\right],\qquad q^{\otimes}=\left[\begin{array}{cc}s &amp; -v^{T}\v &amp; sI-v^{\wedge}\end{array}\right]\end{equation}\tag{1.65}$$四元数的运算有以下性质：$$\begin{equation}q_{1}q_{2}=q_{1}^{+}q_{2}=q_{2}^{\otimes}q_{1}\end{equation}\tag{1.66}$$我们希望得到$\dot{\delta\theta}$这个关于角度误差的方程，我们根据下面的方程$$\begin{eqnarray}\dot{q}{t} &amp; =\frac{1}{2}q{t}\otimes\omega_{t}= &amp; \frac{1}{2}q_{t}\otimes(\tilde{\omega}-b_{gt}-\eta_{g})\tag{1.67}\end{eqnarray}$$ $$\begin{eqnarray}\dot{q} &amp; =\frac{1}{2}q\otimes\omega= &amp; \frac{1}{2}q\otimes(\tilde{\omega}-b_{g})\end{eqnarray}\tag{1.68}$$ 分别是四元数真值和名义状态变量导数的定义，注意，这里面的$\omega_{t}$和$\omega$都是四元数。 针对公式$(1.67)$，我们针对左右两侧分别计算$$\begin{eqnarray}(\dot{q\delta q})= &amp; \boxed{\dot{q_{t}}} &amp; =\frac{1}{2}q_{t}Exp(\omega_{t}) \\dot{q}\delta q+q\dot{\delta q}= &amp; &amp; =\frac{1}{2}q\delta qExp(\omega_{t})\\frac{1}{2}qExp(\omega)\delta q+q\dot{\delta q}= &amp; &amp; =\frac{1}{2}q\delta qExp(\omega_{t})\end{eqnarray}\tag{1.69}$$ 针对公式$(1.69)$两侧的计算，约掉$q$，并且将$\dot{\delta q}$移到一侧可以得到$$\begin{align}\left[\begin{array}{c}0\\dot{\delta\theta}\end{array}\right]=\boxed{2\dot{\delta q}} &amp; =\delta qExp(\omega_{t})-Exp(\omega)\delta q \ &amp; =q^{\otimes}(\omega_{t})\delta q-q^{+}(\omega)\delta q \ &amp; =\left[q^{\otimes}(\omega_{t})-q^{+}(\omega)\right]\delta q \ &amp; =\left[\left[\begin{array}{cc}0 &amp; -\omega_{t}^{T}\\omega_{t} &amp; -\omega_{t}^{\wedge}\end{array}\right]-\left[\begin{array}{cc}0 &amp; -\omega^{T}\\omega &amp; \omega^{\wedge}\end{array}\right]\right]\left[\begin{array}{c}cos\frac{\delta\theta}{2}\sin\frac{\delta\theta}{2}\end{array}\right]\ &amp; =\left[\begin{array}{cc}0 &amp; -\omega_{t}^{T}+\omega^{T}\\omega_{t}-\omega &amp; -\omega_{t}^{\wedge}-\omega^{\wedge}\end{array}\right]\left[\begin{array}{c}cos\frac{\delta\theta}{2}\sin\frac{\delta\theta}{2}\end{array}\right] \ &amp; \approx\left[\begin{array}{cc}0 &amp; -\omega_{t}^{T}+\omega^{T}\\omega_{t}-\omega &amp; -(\omega_{t}+\omega)^{\wedge}\end{array}\right]\left[\begin{array}{c}1\\frac{\delta\theta}{2}\end{array}\right]\end{align}\tag{1.70}$$ 这样就分别得到一个标量等式，$$\begin{align}0 &amp; =(-\omega_{t}+\omega)^{T}\delta\theta\end{align}\tag{1.71}$$还有一个向量等式，$$\begin{align}\dot{\delta\theta} &amp; =\omega_{t}-\omega-\frac{1}{2}(\omega_{t}+\omega)^{\wedge}\delta\theta \ &amp; =((\tilde{\omega}-b_{gt}-\eta_{g})-(\tilde{\omega}-b_{g}))-\frac{1}{2}((\tilde{\omega}-b_{gt}-\eta_{g})+(\tilde{\omega}-b_{g}))^{\wedge}\delta\theta \ &amp; =-\delta b_{g}-\eta_{g}-\frac{1}{2}(2\tilde{\omega}-2b_{g}-\delta b_{g}-\eta_{g})^{\wedge}\delta\theta\ &amp; =-(\tilde{\omega}-b_{g})^{\wedge}\delta\theta-\delta b_{g}-\eta_{g}+\frac{1}{2}(\delta b_{g}+\eta_{g})^{\wedge}\delta\theta \ &amp; \approx-(\tilde{\omega}-b_{g})^{\wedge}\delta\theta-\delta b_{g}-\eta_{g}\end{align}\tag{1.72}$$ 标量等式都是二阶小量，用处不大。向量等式中第5行同样是省略了二阶小量，得到了角度误差的线性方程：$$\begin{equation}\boxed{\dot{\delta\theta}=-(\tilde{\omega}-b_{g})^{\wedge}\delta\theta-\delta b_{g}-\eta_{g}}\tag{1.73}\end{equation}$$]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>ESKF</tag>
        <tag>quaterninon</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F10%2F18%2FJson%20%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Json 数据格式JSON 语法规则JSON是一个标记符的序列。这套标记符包含六个构造字符、字符串、数字和三个字面名。 JSON是一个序列化的对象或数组。 六个构造字符： begin-array = ws %x5B ws ; [ 左方括号 begin-object = ws %x7B ws ; { 左大括号 end-array = ws %x5D ws ; ] 右方括号 end-object = ws %x7D ws ; } 右大括号 name-separator = ws %x3A ws ; : 冒号 value-separator = ws %x2C ws ; , 逗号 在这六个构造字符的前或后允许存在无意义的空白符**(ws):** ws = *（%x20 /; 空间 %x09 /; 水平标签 %x0A /; 换行或换行 %x0D）; 回程 JSON的值: 3.1 JSON的构成: ws 值 ws [1] 3.2值可以是对象、数组、数字、字符串或者三个字面值(false、null、true)中的一个。值中的字面值中的英文必须使用小写。 ​ 3.2.1 对象由花括号括起来的逗号分割的成员构成，成员是字符串键和上文所述的值由逗号分割的键值对组成，如： 1` ``&#123;``"name"``: ``"John Doe"``, ``"age"``: 18, ``"address"``: &#123;``"country"` `: ``"china"``, ``"zip-code"``: ``"10000"``&#125;&#125;` ​ 3.2.2 数组是由方括号括起来的一组值构成，如： 1`[3, 1, 4, 1, 5, 9, 2, 6]` ​ 3.2.3 字符串与C或者Java的字符串非常相似。字符串是由双引号包围的任意数量Unicode字符的集合，使用反斜线转义。一个字符（character）即一个单独的字符串（character string）。 ​ 3.2.4 数字也与C或者Java的数值非常相似。除去未曾使用的八进制与十六进制格式。除去一些编码细节。 [2] 一些合法的JSON的实例： 1`&#123;``"a"``: 1, ``"b"``: [1, 2, 3]&#125;`]]></content>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下matlab安装]]></title>
    <url>%2F2019%2F04%2F14%2Fubuntu%E4%B8%8Bmatlab%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[ubuntu下安装matlab的记录。 问题：在Ubuntu中使用matlab的时候出现错误提示 “启动出错”，其中包括Java的一些错误。 是因为在home目录下的matlab的隐藏文件权限不够，所以才造成每次打开出现一些提示错误的问题。 解决方法： 在home 按住ctrl +H 键 可以找到.matlab的文件是没有权限的，在command中输入一行命令就ok了： sudo chmod 777 .matlab -R 解决方法如下：进入Maltab的安装路径：进入JRE目录： cd Matlab目录/sys/java/jre/glnx64/jre/lib/fonts 新建fallback文件夹： sudo mkdir fallback #可以尝试不建立fallback，我没有实验 复制字体到fallback目录中： cp 该字体文件夹/wqy-zenhei.ttc fallback/ #大家推荐这个字体，可以用别的，可以自己下载其他字体 进入fallback目录，执行： mkfontscale 修改font.dir权限： cd ..sudo chmod 777 fonts.dir #直接777一步到位cat fallback/fonts.scale &gt;&gt; fonts.dir #添加上一步生成的.scale到.dir中]]></content>
      <categories>
        <category>ubuntu</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[成像畸变校正]]></title>
    <url>%2F2019%2F03%2F30%2F%E6%88%90%E5%83%8F%E7%95%B8%E5%8F%98%2F</url>
    <content type="text"><![CDATA[对图像畸变进行校正。]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>kinect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界、相机、图像和像素坐标之间的转换]]></title>
    <url>%2F2019%2F03%2F29%2F%E4%B8%96%E7%95%8C%E3%80%81%E7%9B%B8%E6%9C%BA%E3%80%81%E5%9B%BE%E5%83%8F%E5%92%8C%E5%83%8F%E7%B4%A0%E5%9D%90%E6%A0%87%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[主要对摄像机成像原理和世界、相机、图像和像素坐标之间的转换关系进行介绍。 四个坐标理解四个坐标之间的几何关系。 图像处理中涉及到以下四个坐标系： $O_w-X_wY_wZ_w$:世界坐标系，描述相机位置，单位:m $O_c-X_cY_cZ_c$:相机坐标系，光心为原点，单位：m $Oxy$: 图像坐标系，光心为图像中点，单位：mm $uv$: 像素坐标系，原点为图像左上角，单位：pixel $P$: 世界坐标系中的一点，即为生活中真实的一点； $p$: 点$P$在图像中的成像点，在图像坐标系中的坐标为$(x,y)$,在像素坐标系中的坐标为$(u,v)$; $f$: 相机焦距，等于$o$与$O_c$的距离，$f=||o-O_c||$。 世界坐标系和相机坐标系之间的转换 从世界坐标系变换到相机坐标系属于刚体变换：即物体不会发生形变，只需要进行旋转和平移。$R$:表示旋转矩阵；$T$:表示平移矩阵。$$\left[\begin{matrix}X_c\\ Y_c \\Z_c\end{matrix}\right] = R \left[\begin{matrix} X_w \\Y_w \\Z_w\end{matrix}\right]+T$$ 以齐次坐标表示：$$\left[\begin{matrix}X_c\\ Y_c \\Z_c\\1\end{matrix}\right] = \left[\begin{matrix}R_{3\times 3}&amp; T_{3\times 1}\\ 0 &amp; 1\end{matrix}\right] \left[\begin{matrix} X_w \\Y_w \\Z_w\\1 \end{matrix}\right]$$ 相机坐标系到图像坐标系之间的转换 从相机坐标系到图像坐标系是从3D转换到2D，属于透视投影关系，以下是推导过程： $\triangle ABO_c\sim\triangle oCO_c$$\triangle PBO_c\sim\triangle pCO_c$ $$\frac{AB}{oC}=\frac{AO_c}{oO_c}=\frac{PB}{pC}=\frac{X_c}{x}=\frac{Z_c}{f}=\frac{Y_c}{y}$$ $$x=f\frac{X_c}{Z_c},y=\frac{Y_c}{Z_c}$$ $$Z_c\left[\begin{matrix}x\\ y\\ 1\end{matrix}\right]=\left[\begin{matrix}f&amp;0&amp;0&amp;0\\ 0&amp;f&amp;0&amp;0\\ 0&amp;0&amp;1&amp;0\end{matrix}\right]\left[\begin{matrix}X_c\\ Y_c\\ Z_c\\ 1\end{matrix}\right]$$ 很明显，$Z_c$是空间点$P$的深度信息。此时，投影点$p$的单位还是mm，并不是像素pixel，需要进一步转换到像素坐标系。 图像坐标系到像素坐标系之间的转换像素坐标系和图像坐标系都在成像平面上，只是各自的原点和度量单位不一样。图像坐标系的原点为相机光轴与成像平面的交点，通常情况下是成像平面的中点或者叫principal point。图像坐标系的单位是mm，是物理单位，而像素坐标系的单位是pixel，我们平常描述一个像素点都是几行几列。所以这两者之间的转换关系如下： $$u=\frac{x}{dx}+u_0$$$$v=\frac{y}{dy}+v_0$$ 其中，$dx$和$dy$分别表示每一列和每一行分别代表多少mm，即$1pixel = dx mm$。 以齐次坐标形式表示为： $$\left[\begin{matrix}u\\ v\\ 1\end{matrix}\right] = \left[\begin{matrix}\frac{1}{dx} &amp; 0 &amp;u_0\\ 0&amp;\frac{1}{dy}&amp; v_0\\0&amp; 0&amp; 1\end{matrix}\right]\left[\begin{matrix}x\\ y\\ 1\end{matrix}\right]$$ 最后总结起来： \begin{align}Z_c\left[\begin{matrix}u\\ v\\ 1\end{matrix}\right]&amp;=\left[\begin{matrix}\frac{1}{dx} &amp; 0 &amp;u_0\\ 0&amp;\frac{1}{dy}&amp; v_0\\0&amp; 0&amp; 1\end{matrix}\right]\left[\begin{matrix}f&amp;0&amp;0&amp;0\\ 0&amp;f&amp;0&amp;0\\ 0&amp;0&amp;1&amp;0\end{matrix}\right]\left[\begin{matrix}R_{3\times 3}&amp; T_{3\times 1}\\ 0 &amp; 1\end{matrix}\right]\left[\begin{matrix} X_w \\Y_w \\Z_w\\1 \end{matrix}\right]\\&amp;=\left[\begin{matrix}f_x&amp;0&amp;u_0&amp;0\\ 0&amp;f_y&amp;v_0&amp;0\\ 0&amp;0&amp;1&amp;0\end{matrix}\right]\left[\begin{matrix}R_{3\times 3}&amp; T_{3\times 1}\\ 0 &amp; 1\end{matrix}\right]\left[\begin{matrix} X_w \\Y_w \\Z_w\\1 \end{matrix}\right]\end{align} 其中，$\left[\begin{matrix}f_x&amp;0&amp;u_0&amp;0\\ 0&amp;f_y&amp;v_0&amp;0\\ 0&amp;0&amp;1&amp;0\end{matrix}\right]$为相机内参。$\left[\begin{matrix}R_{3\times 3}&amp; T_{3\times 1}\\ 0 &amp; 1\end{matrix}\right]$为相机外参。 $Z_c$是深度信息：所以一个空间中的坐标点，可以在图像中找到一个对应的像素点，但是，通过图像中的一个点找到它在空间中对应的点就很难。因为$Z_c$（深度信息）未知。－－－－－－－－－－－－－－－－－－－－－－以上（相机的内参和外参）都可以通过张正友标定获取。－－－－－－－－－－－－－－－－－－－－－－]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
        <tag>kinect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全景图像拼接]]></title>
    <url>%2F2019%2F03%2F06%2FPanoramic%20stitching%2F</url>
    <content type="text"><![CDATA[本文主要记录全景图像拼接，此记。 1,特征点提取方法有SIFT，SURF，ORB，这三种方法在OpenCV里面都已实现，如果装的是opencv2.0版本，则可以直接用SURF，如果是3.0版本，则需要下载相应的contrib库进行安装。其中SIFT是最为经典的一种，它充分考虑了在图像变换过程中出现的光照、尺度、旋转等变化，但随之而来的是极大的计算量。SURF是加速版的SIFT，SURF基本就是SIFT的全面升级版，有SURF基本就不用考虑SIFT，而ORB的强点在于计算时间，考虑到视频拼接的实时性要求，采用ORB特征点提取。 在对应好相应图像拼接帧后，利用上一章介绍的图像拼接算法进行图像拼接，可以保证图像拼接的质量。但是在保证质量的同时，也要兼顾拼接速度。考虑到实用性，此图像拼接算法耗费的时间过多，根本无法用来做视频拼接，因此需要对算法进行优化，都思路进行拓展。其中优化措施有以下几点： 固定摄像头位置，保证相机参数不改变。 打开摄像头，采集图像，为了消除摄像头刚开始采集图像时，摄像头之间存在一定的初始化时间差异这一现象，先等待摄像头稳定，再读取摄像头图像帧进行图像拼接，此拼接图像作为视频拼接的背景帧，选取的背景一定要是静态的。 对后续帧序列，由于相机位置是固定的，可以不再进行特征点提取、匹配、筛选以及相机参数计算等步骤，即变换矩阵不再逐帧计算，而是利用背景帧的拼接参数做处理，只对后续帧序列进行图像融合，从而生成拼接视频流。 通过该思路可看出，后续对应帧的拼接速度仅仅取决于图像融合的速度，也即是图像融合的速度决定视频拼接的速度。因为省去了每一对应图像帧的图像配准和图像变换，只进行图像采集，图像预处理和图像融合，大大减少了视频拼接的时间，提高了拼接图像的帧率。在兼顾质量的同时，也提高了速度。 得到背景帧之后，在重合区域内检测是否存在运动的物体，如果存在，则更新背景模板及获得新的拼接参数，如果不存在，则继续使用当前背景帧的相关参数进行后续帧的拼接。 因为检测的代价远远小于模板更新的代价，对每一拼接帧的重合区域进行运动物体检测，有选择性的更新背景模板，将可以极大地提高拼接速度，并且一定程度的地消除运动物体穿过缝合线时产生的虚影。]]></content>
      <categories>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kinect彩色图和深度图对齐(二)]]></title>
    <url>%2F2019%2F01%2F24%2Fkinect_calibrator_1%2F</url>
    <content type="text"><![CDATA[本文主要记录kinect相关的知识和对齐方法，这是第二部分，此记。 kinect驱动安装在上一篇已经完成，测试没问题，那么现在开始kinect彩色图和深度图的对齐工作。 Kinect彩色图和红外图获取Kinect的深度图实际上是由IR相机（红外相机）形成的，因此，本质上做的是彩色图和红外图像的对齐。因此，需要先获取彩色图像和红外图像，图像的获取方法应该是多样的，比如通过ros利用freenect功能包启动kinect，通过image_view订阅相关话题显示彩色图和红外图像，问题是我在订阅红外图像的时候总是不显示，全是黑色一片，只订阅红外图像话题仍然存在这个问题，尝试过很多方法都不行，考虑到一个原因就是kinect v1不能同时显示彩色图像和红外图像，但是在rviz中显示就没有问题，很费解！ 此方法行不通后，考虑自己写代码实现，参考了一些资料后，成功实现彩色图像和红外图像的采集保存。代码及相应的配置文件如下，为保证文章的连续性，代码的说明放在另一篇幅中（链接）。 main.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140#include &lt;stdlib.h&gt;#include &lt;iostream&gt;#include &lt;string&gt;//【1】#include &lt;XnCppWrapper.h&gt;#include "opencv/cv.h"#include "opencv/highgui.h"using namespace std;using namespace cv;//图像的宽度和高度，注意顺序#define Depth_Width 640#define Depth_Height 480#define Rgb_Width 640#define Rgb_Height 480#define Ir_Width 640#define Ir_Height 480void CheckOpenNIError( XnStatus result, string status )&#123; if( result != XN_STATUS_OK ) cerr &lt;&lt; status &lt;&lt; " Error: " &lt;&lt; xnGetStatusString( result ) &lt;&lt; endl;&#125;int main( int argc, char** argv )&#123; XnStatus result = XN_STATUS_OK; xn::DepthMetaData depthMD; xn::ImageMetaData imageMD; xn::IRMetaData irMD; //OpenCV //IplImage* cvCreateImage(CvSize cvSize(int width, int height), //int depth, int channels); //如果我们要创建一个宽为360,高为640的3通道图像（RGB图像）， //可以采用如下语句： //IplImage* img=cvCreateImage( cvSize(360,640), IPL_DEPTH_8U,3 ); IplImage* imgDepth16u=cvCreateImage(cvSize(Depth_Width,Depth_Height), IPL_DEPTH_16U,1); IplImage* imgRGB8u=cvCreateImage(cvSize(Rgb_Width,Rgb_Height), IPL_DEPTH_8U,3); IplImage* imgIR16u = cvCreateImage(cvSize(Ir_Width,Ir_Height), IPL_DEPTH_16U,1); IplImage* depthShow=cvCreateImage(cvSize(Depth_Width,Depth_Height), IPL_DEPTH_8U,1); IplImage* imageShow=cvCreateImage(cvSize(Rgb_Width,Rgb_Height), IPL_DEPTH_8U,3); IplImage* irShow = cvCreateImage(cvSize(Ir_Width,Ir_Height), IPL_DEPTH_8U,1); // create window cvNamedWindow("depth",1); cvNamedWindow("image",1); cvNamedWindow("ir",1); char key=0; //【2】 // context xn::Context context; result = context.Init(); CheckOpenNIError( result, "initialize context" ); // creategenerator xn::DepthGenerator depthGenerator; result = depthGenerator.Create( context ); CheckOpenNIError( result, "Create depth generator" ); xn::ImageGenerator imageGenerator; result = imageGenerator.Create( context ); CheckOpenNIError( result, "Create image generator" ); xn::IRGenerator irGenerator; result = irGenerator.Create( context ); CheckOpenNIError( result, "Create ir generator" ); //【3】 //map mode XnMapOutputMode mapMode; mapMode.nXRes = 640; mapMode.nYRes = 480; mapMode.nFPS = 30; result = depthGenerator.SetMapOutputMode( mapMode ); result = imageGenerator.SetMapOutputMode( mapMode ); result = irGenerator.SetMapOutputMode( mapMode); //【4】 // correct view port depthGenerator.GetAlternativeViewPointCap().SetViewPoint( imageGenerator ); //【5】 //read data result = context.StartGeneratingAll(); //【6】 result = context.WaitNoneUpdateAll(); long currentFrame = 0; while( (key!=27) &amp;&amp; !(result = context.WaitNoneUpdateAll( )) ) &#123; //get meta data depthGenerator.GetMetaData(depthMD); imageGenerator.GetMetaData(imageMD); irGenerator.GetMetaData(irMD); stringstream str; str &lt;&lt; "stamp" &lt;&lt; currentFrame &lt;&lt; ".jpg"; //【7】 //OpenCV output memcpy(imgDepth16u-&gt;imageData,depthMD.Data(),640*480*2); cvConvertScale(imgDepth16u,depthShow,255/4096.0,0); memcpy(imgIR16u-&gt;imageData,irMD.Data(),640*480*2); cvConvertScale(imgIR16u,irShow,1,0);; memcpy(imgRGB8u-&gt;imageData,imageMD.Data(),640*480*3); cvCvtColor(imgRGB8u,imageShow,CV_RGB2BGR); cvShowImage("depth", depthShow); cvShowImage("image",imageShow); cvShowImage("ir",irShow); cvShowImage("ir",irShow); if (currentFrame % 30 == 0) &#123; cvSaveImage("rgb.jpg",imageShow); cvSaveImage("depth.png",depthShow); cvSaveImage("ir.png",irShow); &#125; key=cvWaitKey(20); currentFrame++; &#125; //destroy cvDestroyWindow("depth"); cvDestroyWindow("image"); cvDestroyWindow("ir"); cvReleaseImage(&amp;imgDepth16u); cvReleaseImage(&amp;imgRGB8u); cvReleaseImage(&amp;imgIR16u); cvReleaseImage(&amp;depthShow); cvReleaseImage(&amp;imageShow); cvReleaseImage(&amp;irShow); context.StopGeneratingAll(); context.Release(); return 0;&#125; CMakeLists.txt1234567891011cmake_minimum_required(VERSION 2.8)project(hellokinect) # 寻找OpenCV库 find_package( OpenCV REQUIRED ) # 添加头文件 include_directories( $&#123;OpenCV_INCLUDE_DIRS&#125; ) # 包含OpenNI库 include_directories ("/usr/include/ni/" ) add_executable(hellokinect main.cpp) target_link_libraries( hellokinect OpenNI $&#123;OpenCV_LIBS&#125;) 创建图像包含三个元素： 图像的大小 图像的深度 图像的通道 depth 图像元素的位深度，可以是下面的其中之一： 位深度 取值范围 IPL_DEPTH_8U - 无符号8位整型 0–255 IPL_DEPTH_8S - 有符号8位整型 -128–127 IPL_DEPTH_16U - 无符号16位整型 0–65535 IPL_DEPTH_16S - 有符号16位整型 -32768–32767 IPL_DEPTH_32S - 有符号32位整型 0–65535 IPL_DEPTH_32F - 单精度浮点数 0.0–1.0 IPL_DEPTH_64F - 双精度浮点数 0.0–1.0 位深度转换原理如上，给出图像的位深度及其取值范围后，我们不难理解，要转换位深度本质上就是对原深度下的数据做线性变换，使原位深度下的最小值和最大值分别对应转换后位深度下的最小值和最大值。实现上述线性变换，我们可以用opencv库函数cvConvertScale。 图像的通道比较通俗易懂的解释是：灰度图的通道数为1，彩色图的通道为3。基本上，描述一个像素点，如果是灰度，那么只需要一个数值来描述它，就是单通道。如果一个像素点，有RGB三种颜色来描述它，就是三通道。 Kinect彩色图和深度图对准MATLAB对准方法将得到的彩色图像和红外图像分为两组，然后利用MATLAB的stereoCameraCalibrator工具箱，输入两组图像，然后点击calibrate即可得到两个相机的坐标变换旋转矩阵$R$和平移矩阵$T$，MATLAB得到的矩阵$\hat{R}$需要转置后才是旋转矩阵$R$.stereoCameraCalibrator工具箱链接 Kinect彩色图和深度图对准理论方法kinect RGB的内参:$$K_{rgb} =\left[\begin{matrix}f_{x_rgb} &amp; 0 &amp; c_{x_rgb}\\0 &amp; f_{y_rgb} &amp; c_{y_rgb}\\0 &amp; 0 &amp; 1\end{matrix}\right] =\left[\begin{array}{ccc}522.955354 &amp; 0.000000 &amp; 327.140468\\0.000000 &amp; 523.763483 &amp; 218.630165\\0.000000 &amp; 0.000000 &amp; 1.000000\end{array}\right]$$因此，对于各自相机坐标系下的齐次的三维点($P=[X,Y,Z,1]^T$)到各自图片上齐次表示的像素坐标($p=[u,v,1]^T$)的映射关系如下： 对彩色相机而言，有： $$Z_{rgb}\cdot p_{rgb} = K_{rgb}\cdot [I|O]\cdot P_{rgb}$$展开如下， \begin{aligned}Z_{rgb}\cdot \left[\begin{array}{c}u_{rgb}\\v_{rgb}\\1\end{array}\right]&amp; = \left[\begin{array}{c}f_{x_rgb}\cdot X_{rgb}+c_{x_rgb}\cdot Z_{rgb}\\f_{y_rgb}\cdot Y_{rgb}+c_{y_rgb}\cdot Z_{rgb}\\Z_{rgb}\end{array}\right] \\&amp; =\left[\begin{array}{cccc}f_{x_rgb} &amp; 0 &amp; c_{x_rgb} &amp; 0\\0 &amp; f_{y_rgb} &amp; c_{y_rgb} &amp; 0\\0 &amp; 0 &amp; 1&amp; 0\end{array}\right]\cdot \left[\begin{array}{c}X_{rgb}\\Y_{rgb}\\Z_{rgb}\\1\end{array}\right]\end{aligned} 其中，齐次坐标$P_{rgb} = [X_{rgb},Y_{rgb},Z_{rgb} 1]^T$我们可以用非齐次坐标$\bar{P_{rgb}}=[X_{rgb},Y_{rgb},Z_{rgb}]$来表示，应有如下的形式： $$Z_{rgb}\cdot p_{rgb} = K_{rgb}\cdot \bar{P_{rgb}}$$ kinect Depth(ir)的内参:\begin{equation}K_{ir} =\left[\begin{array}{ccc}f_{x_ir} &amp; 0 &amp; c_{x_ir}\\0 &amp; f_{y_ir} &amp; c_{y_ir}\\0 &amp; 0 &amp; 1\end{array}\right] =\left[\begin{array}{ccc}605.290291 &amp; 0.000000 &amp; 333.064832\\0.000000 &amp; 606.360112 &amp; 205.426105\\0.000000 &amp; 0.000000 &amp; 1.000000\end{array}\right]\end{equation} 同理，可得到深度相机的映射公式：$$Z_{ir}\cdot p_{ir} = K_{ir}\cdot \bar{P_{ir}}$$ 针对于同一幅棋盘的外参(MATLAB的cameraCalibrator可以实现内/外参标定): 彩色相机：$R_{rgb}$和$T_{rgb}$ 深度相机：$R_{ir}$和$T_{ir}$ 因此，两个相机有如下刚体变换关系：$$R_{ir2rgb} = R_{rgb}\cdot R_{ir}^{-1}$$$$T_{ir2rgb} = T_{rgb} - R_{ir2rgb}\cdot T_{ir}$$ 对于非齐次坐标表示的各自相机坐标系下的三维点$\bar{P_{rgb}}$和$\bar{P_{ir}}$来说，有如下关系：$$\bar{P_{rgb}} = R_{ir2rgb}\cdot \bar{P_{ir}} + T_{ir2rgb}$$ 最后，我们可以得到如下公式：$$Z_{rgb}\cdot p_{rgb} = K_{rgb}\cdot R_{ir2rgb}\cdot K_{ir}^{-1}\cdot Z_{ir}\cdot p_{ir}+K_{rgb}\cdot T_{ir2rgb}$$ 这样就把$p_{rgb}$和$p_{ir}$联系起来了。 为了简化表示，我们令：$$R = K_{rgb}\cdot R_{ir2rgb}\cdot K_{ir}^{-1}$$$$T = K_{rgb}\cdot T_{ir2rgb}$$ 则有，$$Z_{rgb}\cdot p_{rgb} = R\cdot Z_{ir}\cdot p_{ir}+T$$]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>kinect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kinect彩色图和深度图对齐(三)：代码注释说明]]></title>
    <url>%2F2019%2F01%2F24%2Fkinect_calibrator_2%2F</url>
    <content type="text"><![CDATA[本文主要记录kinect相关的知识和对齐方法，这是第三部分，主要是代码说明，此记。 【1】XnCppWrapper.h是OpenNI的头文件，opencv/cv.h和opencv/highgui.h是opencv的一些头文件，关于opencv库内容可以参见书籍《openCV3编程入门》或OpenCV入门教程 。关于OpenNI库内容，可以看一个博客对官方文档的翻译OpenNI2 开发者指南。 【2】四个首地址imgDepth16u，imgRGB8u， depthShow， imageShow是由cvCreateImage()函数创建的，查询百度百科了解到函数功能是创建首地址并分配存储空间，用法是：header = cvCreateImageHeader(size,depth,channels);size 图像宽、高.depth 图像元素的位深度，可以是下面的其中之一：IPL_DEPTH_8U - 无符号8位整型IPL_DEPTH_8S - 有符号8位整型IPL_DEPTH_16U - 无符号16位整型IPL_DEPTH_16S - 有符号16位整型IPL_DEPTH_32S - 有符号32位整型IPL_DEPTH_32F - 单精度浮点数IPL_DEPTH_64F - 双精度浮点数channels 每个元素（像素）通道数.可以是 1, 2, 3 或 4.通道是交叉存取的。header是返回的数据块首地址。关于图像基础内容，可以参看博客：opencv中图像基础（大小，深度，通道）。 【3】OpenNI::initialize()方法。这个方法初始化所有的传感器驱动并且扫描系统中所有可用的传感器设备。所有使用OpenNI的应用程序在使用其他API之前都应该调用此方法。上下文对象(context object)是OpenNI的主对象，它包括（使用OpenNI的程序的）所有状态信息，以及这个程序使用的所有产品链。同一个程序可以创建多个上下文，但是它们不可以共享信息。上下文对象在使用前必须先被初始化，这个时候所有的内置模块都被加载。【4】能产生数据的产品节点叫做generator（DepthGenerator和ImageGenerator），一旦它们被创建，并不立即开始产生数据，允许程序来设置所需的配置。这能够保证一旦这些对象开始抽取数据到程序，这些数据是根据所需配置产生的。数据生成器在没有指明被要求去产生数据的话，不会自己产生数据。 【5】XnMapOutputMode是用来设定生成器的参数，GetAlternativeViewPointCap().SetViewPoint( )函数是用来调整视角的。 【6】StartGeneratingAll()函数是打开图像数据收集开关。而为了确保能取得最新的数据，在读取 Generator 的数据前，都必须要先呼叫 context 的 wait / update 这一系列的函式，来进行 node 数据的更新。这系列的函示有四个：WaitAnyUpdateAll()、WaitOneUpdateAll()、WaitNoneUpdateAll() 和 WiatAndUpdateAll()。这四者都会更新 context 下所有的 node 的数据，差别只在于更新的条件：WiatAndUpdateAll() 会等到所有的 node 都取得新数据后，再统一更新所有的 node 的数据；WaitAnyUpdateAll() 是等到随便一个 node 有新数据时就会更新；WaitOneUpdateAll() 则是等到指定的 node 有新数据时再更新；WaitNoneUpdateAll() 则是不管有没有新数据就强制更新。 【7】depthGenerator.GetMetaData是获取生成器里的数据并放在depthMD缓冲器中。 【8】OpenNI支持的图像格式比较单一，需要用OpenCV进行下一步操作，则需要将DepthMetaData、ImageMetaData转换为Mat数据类型，详见博客文章。memcpy指的是c和c++使用的内存拷贝函数，memcpy函数的功能是从源src所指的内存地址的起始位置开始拷贝n个字节到目标dest所指的内存地址的起始位置中。程序中memcpy()函数的作用是将深度数据复制到imgDepth16U.imageData,图像大小为640*480,2通道（2个字节） 。这里深度数据为什么是两个字节，相信都有疑惑。经查询资料了解到，Kinect的深度图像数据含有两种格式，两种格式都是用两个字节来保存一个像素的深度值，而两方式的差别为：（1）唯一表示深度值：那么像素的低12位表示一个深度值，高4位未使用； （2）既表示深度值又含有游戏者ID：Kinect SDK具有分析深度数据和探测人体或者游戏者轮廓的功能，它一次能够识别多达6个游戏者。SDK为每一个追踪到的游戏者编号作为索引。而这个方式中，像素值的高13位保存了深度值，低三位保存用户序号，7 (0000 0111)这个位掩码能够帮助我们从深度数据中获取到游戏者索引值（这个编程将在下一节）。 应用程序可以使用深度数据流中的深度数据来支持各种各样的用户特性，如追踪用户的运动并在程序中识别和忽略背景物体的信息等。 【9】cvConvertScale()函数作用是使用线形变换转换数据，255/4096比例压缩，转换到0-255范围。至于为什么，应该是电脑屏幕的正常显示（也即opencv的图像显示）的要求吧。 【10】cvWaitKey()函数的功能是不断刷新图像，频率时间为delay，单位为ms。返回值为当前键盘按键值。经查询，键值为27的是电脑键盘上的ESC退出键。 【11】最后调用CV库中的函数关闭窗口，释放内存空间。用StopGeneratingAll()函数关闭数据收集开关，用context.Shutdown()方法关闭所有驱动并且正确地清除所有。 整合自以下博客： [1]https://blog.csdn.net/qq_36355662/article/details/76747290[2]https://blog.csdn.net/zouxy09/article/details/8146719]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>kinect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kinect彩色图和深度图对齐(一)]]></title>
    <url>%2F2019%2F01%2F23%2Fkinect_calibrator%2F</url>
    <content type="text"><![CDATA[本文主要记录kinect相关的知识和对齐方法，这是第一部分，此记。 深度相机成像方法简介深度相机就是可以获取场景中物体距离摄像头物理距离的相机。深度相机通常由多种镜头和光学传感器组成，根据测量原理不同，主流的深度相机一般分为以下几种方法：飞行时间法（ToF）、结构光法、双目立体视觉法。 飞行时间是从Time of Flight直译过来的，简称TOF。其测距原理是通过连续发射经过调制的特定频率的光脉冲（一般为不可见光）到被观测物体上，然后接收从物体反射回去的光脉冲，通过探测光脉冲的飞行（往返）时间来计算被测物体离相机的距离。微软的Kinect V2采用的就是ToF方案。 结构光法就是使用提前设计好的具有特殊结构的图案（比如离散光斑、条纹光、编码结构光等），将图案投影到三维空间物体表面上，使用另外一个相机观察在三维物理表面成像的畸变情况。如果结构光图案投影在该物体表面是一个平面，那么观察到的成像中结构光的图案就和投影的图案类似，没有变形，只是根据距离远近产生一定的尺度变化。但是，如果物体表面不是平面，那么观察到的结构光图案就会因为物体表面不同的几何形状而产生不同的扭曲变形，而且根据距离的不同而不同，根据已知的结构光图案及观察到的变形，就能根据算法计算被测物的三维形状及深度信息。微软的Kinect V1采用的就是基于结构光的光编码方案。 结构光法优缺点总结 根据前面的原理介绍，我们总结一下基于结构光法深度相机的优缺点。 优点 1)、由于结构光主动投射编码光，因而非常适合在光照不足（甚至无光）、缺乏纹理的场景使用。 2)、结构光投影图案一般经过精心设计，所以在一定范围内可以达到较高的测量精度。 3)、技术成熟，深度图像可以做到相对较高的分辨率。 缺点 1）、室外环境基本不能使用。这是因为在室外容易受到强自然光影响，导致投射的编码光被淹没。增加投射光源的功率可以一定程度上缓解该问题，但是效果并不能让人满意。 2）、测量距离较近。物体距离相机越远，物体上的投影图案越大，精度也越差（想象一下手电筒照射远处的情景），相对应的测量精度也越差。所以基于结构光的深度相机测量精度随着距离的增大而大幅降低。因而，往往在近距离场景中应用较多。 3)、容易受到光滑平面反光的影响。 双目立体视觉法的原理和人眼类似，通过计算空间中同一个物体在两个相机成像的视差就可以根据如下三角关系计算得到物体离相机的距离。 Kinect简介 Kinect有三个镜头，中间的镜头是RGB彩色摄影机，用来采集彩色图像。左右两边镜头则分别为红外线发射器和红外线CMOS摄影机所构成的3D结构光深度感应器，用来采集深度数据（场景中物体到摄像头的距离），Kinect采用了“光编码”的方式，读取投射的红外线光谱，通过反射斑点（称为散斑）的变形来取得纵向的深度的信息。彩色摄像头最大支持1280×960分辨率成像，红外摄像头最大支持640×480成像，最高输出速度为30fps。Kinect还搭配了追焦技术，底座马达会随着对焦物体移动跟着转动。Kinect也内建阵列式麦克风，由四个麦克风同时收音，比对后消除杂音，并通过其采集声音进行语音识别和声源定位。 Kinect V1的Kinect V2的对比Kinect v1深度相机拥有一个RGB彩色摄像头，一个红外线CMOS摄像机和一个红外发射器。相机的红外线CMOS摄像机和红外发射器以左右水平的方式分布。该相机采用的是以结构光为基础进行改进后的光编码（Light Coding）技术获得物体的深度信息。 Kinect V2采用的是「Time of Flight(TOF)」的方式，通过从投射的红外线反射后返回的时间来取得Depth信息。Depth传感器看不到外观，不过Color Camera旁边是红外线Camera(左)和投射脉冲变调红外线的Porjector（右）。 Kinect 驱动简介:非官方和官方开发包的优缺点官方SDK：长处： 提供了音频支持、调整倾角的转动电机、在全身跟踪骨骼跟踪方面：非标准姿势检測（相对于OpenNi的投降姿势…），头部、手、脚、锁骨检測以及关节遮挡等细节上的处理更为仔细（但精度是否更高还不能确定）。此外，支持多传感器（多台Kinect）； 缺点： 微软对非商业使用的限制。此外，未提供手势识别和跟踪功能，未实现RGB图像/深度图像的互对齐，仅仅是提供了对个体坐标系的对齐。在全身骨骼跟踪中，SDK仅仅计算了关节的位置，并未得出其旋转角度。从可移植的角度来看，SDK beta仅仅能用于Kinect/Win7平台，而OpenNi还至少支持华硕的WAVI Xtion体感设备，今后支持的硬件平台还可能很多其它。相比較而言SDK beta不支持Unity3D游戏引擎、不支持记录/回放数据写入磁盘、不支持原始红外视频数据流、也不支持像OpenNi一样的角色入场和出场的事件响应机制。 非官方OpenNI/NITE：长处： 可用于商业开发、包括手势识别和跟踪功能、可自己主动对齐深度图像和RGB图像，全身跟踪、关节旋转角度计算、看起来性能较好、已有众多游戏产品应用、支持记录/回放数据写入磁盘、支持原始红外视频数据流、支持角色入场和出场的事件响应机制。支持Primesense和华硕的WAVI Xtion硬件平台和windows、Linux和Mac等软件平台。自带的代码全面支持Unity3D游戏引擎。 缺点： 未提供音频功能、不支持调整倾角的转动电机、在全身跟踪骨骼跟踪方面：无法跟踪头部、手、脚和锁骨的旋转动作，须要标准姿势检測（即著名的投降姿势…），关节遮挡等细节上的处理似乎存在算法bug。不能自己主动安装并识别Kinect多机环境。安装过程较为繁琐，特别是NITE还要申请开发证书编码。OpenNi也没有提供可用视频和深度图输入的事件触发机制（但OpenNI提供了类似功能的函数可使用，尽管不是回调函数，可是也非常好用）。 总结： OpenNI最大的优势就是同意跨平台多设备，以及商业应用。但从原始数据的採集和预处理技术上看，微软的SDK似乎更稳定一些，况且还提供了不错的骨骼和语音支持。对于部分身体部位识别方面的功能，SDKbeta没有提供局部识别和跟踪，这须要自己的兴许开发（至少在相当一段时期内微软可能都不会提供此类功能）。OpenNi/NITE尽管提供了手势识别和跟踪，然而在全身骨骼姿势识别和跟踪上还要很多其它借鉴微软的产品。 因此，依照眼下在社区中的表现，SDK beta和OpenNi/NITE孰优孰劣还真无法一下子确定。并且随着越来越多的开发人员增加微软这一方，SDK beta的普及可能会更快，但在更高层次的应用上，对二者的选用往往是须要一定智慧的。 Kinect驱动安装刚开始使用kinect首先需要安装kinect驱动，我的机器环境是：Ubuntu16.04 kinect V1, 驱动分别是：openni/NITE/Sensor这三个包的版本必须匹配才能正常运行，版本号分别是： OpenNI-Bin-Dev-Linux-x64-v1.5.7.10.tar NITE-Bin-Linux-x64-v1.5.2.23.tar SensorKinect093-Bin-Linux-x64-v5.1.2.1 可以在网盘下载，链接: 驱动下载 提取码: 7ckj。 【Tips】 这三个软件包的安装要注意顺序：先安装openni，再安装Sensor，最后安装NITE。 安装方法1,OpenNI12$cd /Home/Downloads/OpenNI-Bin-Dev-Linux-x64-v1.5.7.10$sudo ./install.sh 安装完成后会有成功提示：123456copyingshared libraries...OK........ ***DONE *** 2,SensorKinect和NITI 安装方法相似，12$ cd /Home/Downloads/Sensor-Bin-Linux-x64-v5.1.2.1$ sudo ./install.sh 123$ cd /Home/Downloads/NITE-Bin-Linux-x64-v1.5.2.23$ sudo ./install.sh` 安装完成后同样会有DONE ×××类似的成功提示。 测试方法测试安装成功与否的方法是采用OpenNI自带的例程12$ cd /Home/Downloads/OpenNI-Bin-Dev-Linux-x64-v1.5.7.10/Samples/Bin/x64-Release$ ./NiViewer 如果出现以下kinect画面则配置成功。 另外可以带-u参数卸载这些软件包重新安装1$sudo ./install.sh -u 但是NITE里有专门的uninstall.sh可以运行它来卸载。 ROS环境下的测试如果你安装了ROS，那么还可以通过安装freenect功能包来测试kinect123456$ cd ~/catkin_ws/src$ git clone https://github.com/ros-drivers/freenect_stack.git $ cd ~/catkin_ws/$ catkin_make$ rospack profile$ roslaunch freenect_launch freenect.launch]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
        <tag>kinect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卡尔曼滤波推导]]></title>
    <url>%2F2019%2F01%2F04%2FKalmanFilter%2F</url>
    <content type="text"><![CDATA[本文主要记录卡尔曼滤波的推导过程，此记。 概念卡尔曼滤波，首先说一下，为什么要用“滤波”这个词？ 从带有噪声的数据中找到“最优估计”的过程就是“过滤”掉噪声的过程。卡尔曼滤波是最好的线性估计方法。 建立系统数学模型在实际应用中，我们可以将物理系统的运行过程看作是一个状态转换过程，卡尔曼滤波将状态空间理论引入到对物理系统的数学建模过程中来，其假设系统状态可以用$n$维空间的一个向量$X\in R^n$来表示。为了描述方便，我们作以下假设：1物理系统的状态转换过程可以描述为一个离散时间的随机过程;2系统状态受控制输入的影响；3系统状态及观测过程都不可避免受噪声影响;4对系统状态是非直接可观测的。 在以上假设前提下，定义系统状态变量为$x_k\in R^n$，系统控制输入为$u_k$，系统过程激励噪声为$w_k$,可得出系统的状态随机差分方程为： $$x_k=Ax_{k-1}+Bu_{k-1}+w_{k-1}\tag{1}$$ 定义观测变量$z_k\in R^m$，观测噪声为$v_k$，得到量测方程： $$z_k=Hx_k+v_k\tag{2}$$ 假设$w_k,v_k$为相互独立，正态分布的白色噪声，过程激励噪声协方差矩阵为$Q$，观测噪声协方差矩阵为$R$，即： $$p(w)\sim N(0,Q)\tag{3}$$ $$p(v)\sim N(0,R)\tag{4}$$ $A,B,H$我们统称为状态变换矩阵，是状态变换过程中的调整系数，是从建立的系统数学模型中导出来的，这儿我们假设它们是常数。 滤波器计算原型 从建立的系统数学模型出发，可以导出卡尔曼滤波的计算原型，包括：时间更新方程和测量更新方程。 为了便于描述，做以下说明：(1)$\hat{x}_k\in R^n$，第$k$步之前的状态已知的情况下第$k$步的先验状态估计值（$\bar{}$代表先验,$\hat{}$代表估计）；(2)$\hat{x}_k\in R^n$ ，测量变量$z_k$已知情况下第$k$步的后验状态估计值。由此定义先验估计误差和后验估计误差： $$e_k^{-}\equiv x_k-\hat{x}_k^{-}\tag{5}$$ $$e_k\equiv x_k-\hat{x}_k\tag{6}\label{pos_estim_error}$$ 先验估计误差的协方差矩阵为： $$P_k^{-}=E(e_k^{-}e_k^{-T})\tag{7}$$ 后验估计误差的协方差矩阵为： $$P_k=E(e_ke_k^{T})\tag{8}\label{pos_estim_error_conv}$$ 先验估计$\hat{X}_k^{-}$和加权的测量变量$Z_k$及其预测$H\hat{X}_k^{-}$之差的线性组合构成了后验状态估计$\hat{X}_k$： $$\hat{x}_k=\hat{x}_k^{-}+K(z_k-\hat{x}_k^{-})\tag{9}\label{pos_estim}$$ 式中测量变量及其预测值之差$(z_k-\hat{X}_k^{-})$ 反映了预测值和实际值之间的不一致程度，称为测量过程的残余。残余为零表明二者完全吻合。$n\times m$阶矩阵$K$叫做残余的增益 ，作用是使\eqref{pos_estim_error_conv}式中的后验估计误差协方差最小。 可以通过以下步骤求出 K：将\eqref{pos_estim}式代入\eqref{pos_estim_error}式代入\eqref{pos_estim_error_conv}式，将$P_k$对$K$求导，使一阶导数为零，可以求出 $K$，$K$的一种形式为： $$K_k = P_k^{-}H^T(HP_k^{-}H^T+R)^{-1}\tag{10}\label{kalman_k}$$ 卡尔曼滤波器用反馈控制的方法估计过程状态： 滤波器估计过程某一时刻的状态， 然后以（含噪声的） 测量变量的方式获得反馈。 因此卡尔曼滤波器可分为两个部分： 时间更新方程和测量更新方程。 时间更新方程负责及时向前推算当前状态变量和误差协方差估计的值， 以便为下一个时间状态构造先验估计。 测量更新方程负责反馈――也就是说， 它将先验估计和新的测量变量结合以构造改进的后验估计。时间更新方程也可视为预估方程， 测量更新方程可视为校正方程。 最后的估计算法成为一种具有数值解的预估－校正算法， 如下图所示。 离散卡尔曼滤波器时间更新方程： $$\hat{x}k^{-} = A\hat{x}{k-1}+Bu_{k-1}\tag{11}$$ $$P_k^{-} = AP_{k-1}A^T + Q\tag{12}$$ 离散卡尔曼滤波器状态更新方程： $$K_k = P_k^{-}H^T(HP_k^{-}H^T+R)^{-1}\tag{13}\label{kalman_gain}$$$$\hat{x}_k=\hat{x}_k^{-}K_k(z_k - H\hat{x}_k^{-})\tag{14}\label{pos_estim2}$$$$P_k = (I-K_kH)P_k^{-}\tag{15}\label{pos_cov}$$ 测量更新方程首先做的是计算卡尔曼增益 $K_k$ 。 注意\eqref{kalman_gain}式和\eqref{kalman_k}式是相同的。 其次便测量输出以获得$z_k$， 然后按\eqref{pos_estim2}式（与\eqref{pos_estim}式相同） 产生状态的后验估计。 最后按\eqref{pos_cov}式估计状态的后验协方差。 最后，滤波器的整个操作流程如下图所示：]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>Kalman Filter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[视觉SLAM十四讲中的知识]]></title>
    <url>%2F2018%2F12%2F21%2FSLAM%20BOOK%2F</url>
    <content type="text"><![CDATA[本文主要记录视觉SLAM十四讲中的相关知识点，此记。 C++知识点智能指针 几乎每一个有分量的程序都需要“在相同时间的多处地点处理或使用对象”的能力。为此，我们必须在程序的多个地点指向（refer to）同一对象。虽然C++语言提供引用（reference）和指针（pointer），还是不够，因为我们往往必须确保当“指向对象”的最末一个引用被删除时该对象本身也被删除，毕竟对象被删除时析构函数可以要求某些操作，例如释放内存或归还资源等等。 所以我们需要“当对象再也不被使用时就被清理”的语义。Class shared_ptr提供了这样的共享式拥有语义。也就是说，多个shared_ptr可以共享（或说拥有）同一对象。对象的最末一个拥有者有责任销毁对象，并清理与该对象相关的所有资源。 shared_ptr的目标就是，在其所指向的对象不再被使用之后（而非之前），自动释放与对象相关的资源。 使用Mat::ptr模板函数123ushort d = depth_.ptr&lt;ushort&gt;(y)[x];//这个还是.ptr模板函数定位像素值的方法，记住用法//返回的是depth_的第y行数据的第x个的深度值 12345678910111213141516171819202122232425262728293031int main()&#123; Mat m(400, 400, CV_8UC3, Scalar(226, 46, 166)); imshow("Before", m); for (int row = 0; row &lt; m.rows; row++) &#123; if (row % 5 == 0) &#123; // data 是 uchar* 类型的, m.ptr&lt;uchar&gt;(row) 返回第 row 行数据的首地址 // 需要注意的是该行数据是按顺序存放的,也就是对于一个 3 通道的 Mat, 一个像素有 // 有 3 个通道值, [B,G,R][B,G,R][B,G,R]... 所以一行长度为: // sizeof(uchar) * m.cols * m.channels() 个字节 uchar* data = m.ptr&lt;uchar&gt;(row); for (int col = 0; col &lt; m.cols; col++) &#123; data[col * 3] = 102; //第row行的第col个像素点的第一个通道值 Blue data[col * 3 + 1] = 217; // Green data[col * 3 + 2] = 239; // Red &#125; &#125; &#125; imshow("After", m); cout &lt;&lt; (int)m.at&lt;Vec3b&gt;(0, 0)[0] &lt;&lt; ','; //利用 Fn 1 介绍的方法输出一下像素值到控制台 cout &lt;&lt; (int)m.at&lt;Vec3b&gt;(0, 0)[1] &lt;&lt; ','; cout &lt;&lt; (int)m.at&lt;Vec3b&gt;(0, 0)[2] &lt;&lt; endl; cvWaitKey(); return 0;&#125; 单件模式（Singleton）定义：单件模式确保一个类只有一个实例，并提供一个全局访问点。把Config写成单件模式（Singleton），它只有一个全局对象，当我们设置参数文件时，创建该对象并读取参数，随后就可以在任意地方访问参数值，最后在程序结束时自动销毁。 std::min_element和std::max_elementReturns an iterator pointing to the element with the smallest（largest） value in the range [first,last).这就是书中使用了std::min_element和lambda表达式的程序，这段程序具体实现的功能是找到matches这个用来存放匹配的关键点的描述子中描述子的最小的距离，然后赋值给min_dis，matches是存放Dmatch这个描述子类的容器，所有最后会有-&gt;distance表示赋给min_dis的是距离。 返回容器或者数组中最大值和最小值。max/min_element(first,end,cmp);其中cmp为可选择参数 1234[] ( const cv::DMatch&amp; m1, const cv::DMatch&amp; m2 ) &#123; return m1.distance &lt; m2.distance; &#125; 这里的lamda函数相当于:1234bool cmp(const cv::DMatch&amp; m1, const cv::DMatch&amp; m2)&#123; return m1.distance &lt; m2.distance; &#125; 实际的功能就是将matches中的所有描述子进行了个排序，然后min_element取了第一个及最小的那个的distance赋给了min_dis c++ 11特性：auto关键字auto可以在声明变量的时候根据变量初始值的类型自动为此变量选择匹配的类型，类似的关键字还有decltype。举个例子：用于代替冗长复杂、变量使用范围专一的变量声明。 想象一下在没有auto的时候，我们操作标准库时经常需要这样：12345678910#include&lt;string&gt;#include&lt;vector&gt;int main()&#123; std::vector&lt;std::string&gt; vs; for (std::vector&lt;std::string&gt;::iterator i = vs.begin(); i != vs.end(); i++) &#123; //... &#125;&#125; 这样看代码写代码实在烦得很。有人可能会说为何不直接使用using namespace std，这样代码可以短一点。实际上这不是该建议的方法（C++Primer对此有相关叙述）。使用auto能简化代码：12345678910#include&lt;string&gt;#include&lt;vector&gt;int main()&#123; std::vector&lt;std::string&gt; vs; for (auto i = vs.begin(); i != vs.end(); i++) &#123; //.. &#125;&#125; for循环中的i将在编译时自动推导其类型，而不用我们显式去定义那长长的一串。在定义模板函数时，用于声明依赖模板参数的变量类型。123456template &lt;typename _Tx,typename _Ty&gt;void Multiply(_Tx x, _Ty y)&#123; auto v = x*y; std::cout &lt;&lt; v;&#125; 若不使用auto变量来声明v，那这个函数就难定义啦，不到编译的时候，谁知道x*y的真正类型是什么呢？模板函数依赖于模板参数的返回值12345template &lt;typename _Tx, typename _Ty&gt;auto multiply(_Tx x, _Ty y)-&gt;decltype(_Tx*_Ty)&#123; return x*y;&#125; 当模板函数的返回值依赖于模板的参数时，我们依旧无法在编译代码前确定模板参数的类型，故也无从知道返回值的类型，这时我们可以使用auto。格式如上所示。 图像知识OpenCV函数函数cvRound，cvFloor，cvCeil 都是用一种舍入的方法将输入浮点数转换成整数： cvRound:返回跟参数最接近的整数值； cvFloor:返回不大于参数的最大整数值；*cvCeil:返回不小于参数的最小整数值。 opencv软件opencv2和opencv3共存opencv2默认安装，安装路径一般是“usr/local”，在安装opencv3时，先下载3的源码，解压后12mkdir buildcd build 更改安装目录（先在/usr/local下新建文件夹opencv3），1cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local/opencv3 .. 然后编译opencv3即可， 12makesudo make install 这样就把3安装在opencv3文件夹了(bin lib share include) build过程中可能报错， ICV: Failed to download ICV package: ippicv_linux_20151201.tgz. Status=7;”Couldn’t connect to server”，解决方法是手动下载ippicv_linux_20151201.tgz，并替换掉opencv-3.1.0/3rdparty/ippicv/downloads/linux-*下的相应文件即可，可以直接从该地址下载：ippicv_linux_20151201.tgz 在使用的时候，在CMakelists.txt中，如要用3，在find_package前指明路径：12set(OpenCV_DIR /usr/local/opencv3/share/OpenCV)find_package(OpenCV 3 REQUIRED) ORB特征构造函数1234567891011121314151617static Ptr&lt;ORB&gt; cv::ORB::create ( int nfeatures = 500, float scaleFactor = 1.2f, int nlevels = 8, int edgeThreshold = 31, int firstLevel = 0, int WTA_K = 2, int scoreType = ORB::HARRIS_SCORE, int patchSize = 31, int fastThreshold = 20 )nfeatures:需要的特征点总数；scaleFactor:尺度因子；nlevels:金字塔层数；edgeThreshold:边界阈值；firstLevel:起始层；WTA_K：描述子形成方法,WTA_K=2表示，采用两两比较；scoreType:角点响应函数，可以选择Harris或者Fast的方法；patchSize:特征点邻域大小；]]></content>
      <categories>
        <category>SLAM</category>
      </categories>
      <tags>
        <tag>SLAM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++谷歌命名法]]></title>
    <url>%2F2018%2F12%2F21%2FC%2B%2B%E8%B0%B7%E6%AD%8C%E5%91%BD%E5%90%8D%E6%B3%95%2F</url>
    <content type="text"><![CDATA[本文主要记录易于理解，通用的C++命名规则，此记。 一般命名规则命名需要尽量是描述性的，避免缩写（特殊情况除外，比如特别常见的缩写num）。 1234int price_count_reader; // 没有缩写int num_errors; // "num" 是常用的惯例int num_dns_connections; // 大多数人都知道“DNS”代表什么int lstm_size; // "LSTM" 在机器学习中是常用的缩写 ！！！！！下面是不推荐的命名方法！！！！！！！！！1234567int n; // 毫无意义的名字.int nerr; // 模糊的缩写.int n_comp_conns; // 模糊的缩写.int wgc_connections; // 估计只有你们自己人知道这是代表什么.int pc_reader; // 很多东西可以简写为"pc".int cstmr_id; // 删除了一些中间的字母.FooBarRequestInfo fbri; // 这甚至都不是一个单词. 一些众所周知，比较常用的缩写是可以的，比如i表示迭代变量，T表示模板参数。 命名规则 类型 命名规则 可用特殊符号 举例 文件名 都是小写字母，可以用下划线“”和破折号“-”，如果没有习惯写法，一般用下划线“” “_”和“-” my_useful_class.cc， my_useful_class.h 类型名 类型名以大写字母开头，以下划线开始 无 类型名包括：classes, structs, type aliases, enums, and type template parameters ，MyExcitingClass, MyExcitingEnum. 变量名（一般变量名） 小写字母，单词之间加下划线 “_” a_local_variable 变量名（类成员变量名） 小写字母，单词之间加下划线，词尾加下划线 “_” a_class_data_member_ 变量名（结构体数据成员名） 小写字母，单词之间加下划线（或单个单词） “_” a_struct_data_member, name,pool 常数命名 常数或常量表达式，需要以小写字母“k”开头，后加大写字母开头的单词，在大写字母无法区分的时候可以添加下划线 “k”,“_” kAndroid8_0_0, kDaysInAWeek 函数名 常规函数名以大写字母开头，访问函数和赋值函数可以像一般变量命名规则一样 访问函数和赋值函数“_” AddTableEntry()，访问函数和赋值函数：int count() ， void set_count(int count) 命名空间 都是小写字母，最上层的命名空间是基于项目名称的，需要避免和常用的命名空间产生歧义 无 websearch 枚举类型名 枚举类型(for both scoped and unscoped enums)参考常数或者宏定义命名规则 “_” kEnumName 或者 ENUM_NAME 宏定义名 宏定义一般不要用，如果必须要用那么应该用全全大写字母，以破折号“_”间隔 “_” MY_MACRO_THAT_SCARES_SMALL_CHILDREN_AND_ADULTS_ALIKE 文件名 my_useful_class.cc my-useful-class.cc myusefulclass.cc myusefulclass_test.cc // _unittest and _regtest are deprecated. 类型名12345678910111213 // classes and structsclass UrlTable &#123; ...class UrlTableTester &#123; ...struct UrlTableProperties &#123; ...// typedefstypedef hash_map&lt;UrlTableProperties *, string&gt; PropertiesMap;// using aliasesusing PropertiesMap = hash_map&lt;UrlTableProperties *, string&gt;;// enumsenum UrlTableErrors &#123; ... 变量名一般变量名1234string table_name; // OK - uses underscore.string tablename; // OK - all lowercase.string tableName; // Bad - mixed case. 类成员变量名1234567class TableInfo &#123; ... private: string table_name_; // OK - underscore at end. string tablename_; // OK. static Pool&lt;TableInfo&gt;* pool_; // OK.&#125;; 结构体数据成员名12345struct UrlTableProperties &#123; string name; int num_entries; static Pool&lt;UrlTableProperties&gt;* pool;&#125;; 常数命名12const int kDaysInAWeek = 7;const int kAndroid8_0_0 = 24; // Android 8.0.0 函数名123AddTableEntry()DeleteUrl()OpenFileOrDie() 特殊的访问函数或赋值函数12int count()void set_count(int count) 命名空间123websearch::indexwebsearch::index_utilwebsearch::index::frobber_internal for use in frobber.h 枚举类型名12345678910enum UrlTableErrors &#123; kOK = 0, kErrorOutOfMemory, kErrorMalformedInput,&#125;;enum AlternateUrlTableErrors &#123; OK = 0, OUT_OF_MEMORY = 1, MALFORMED_INPUT = 2,&#125;; 宏定义名宏定义一般不要用，如果必须要用那么应该用全大写和下划线间隔 12#define ROUND(x) ...#define PI_ROUNDED 3.0 命名规则之外如果你需要对一些C++已有命名规则之外的对象命名，可以参考现有的命名规则。 12345678910bigopen() function name, follows form of open()uint typedefbigpos struct or class, follows form of possparse_hash_map STL-like entity; follows STL naming conventionsLONGLONG_MAX a constant, as in INT_MAX]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS下IMU数据解析并发布-JY901（MPU9250）]]></title>
    <url>%2F2018%2F05%2F24%2FROS%E4%B8%8BIMU%E6%95%B0%E6%8D%AE%E8%A7%A3%E6%9E%90%E5%B9%B6%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[进行ROS下机器人系统开发，需要用到IMU数据，所以需要做IMU数据解析，IMU设备是JY901（内置MPU9250）芯片，设备利用USB转TTL转换，采用了MZ-RS24T转换器，转换芯片为FT232RL，本文想要系统记录从IMU传出数据到数据转换，再到ROS下数据解析并发布IMU话题的过程及（部分）实现方法，此记。 设备连接及通信接口测试设备连接设备连接就是通过MZ-RS24T六合一转换器将TTL电平转换为USB，其中需要注意的就是将发送和接收线交叉连接，如图1所示。 windows下测试设备刚拿到设备需要确认设备是否可用，所以考虑在windows系统下测试，设备应该附带在windows的测试软件（miniIMUV4.3.11）和串口调试软件（SSCOM32），这些可以在他们的官方论坛维特智能上下载到，也可以直接到百度网盘下载，下载链接。windows下的驱动程序可以自动搜索安装就不多说了。 一些具体的测试方法在下载资料的使用说明中有具体的介绍，安装完驱动，确定能识别硬件，验证方法到我的电脑–管理–设备管理器–端口，一般显示为USB Serial Port(COM#)，然后打开miniIMUV4.3.11，可以正常显示在配置中选定的数据，说明硬件正常。 Linux下通信测试插入设备后，通过查看电脑的输入端口确定usb串口号，1ls /dev/tty* 查询到串口名为”/dev/ttyUSB0”，这样说明通信接口正常识别，后边会用的到。如果在后边中通信有问题可能是串口读取权限的问题，可以采用以下方式修改权限。1sudo chmod 666 /dev/ttyUSB0 IMU数据解析JY901模块是一款高精度的姿态测量模块，能够测量被测物体的姿态角度，以欧拉角或者四元素的方式输出。 模块的数据采用16进制的方式进行传输（在使用说明书中也有说明），这种方式的优点是效率高，可以用很少的字节传输需要的数据，比如一个数据1.523，如果用16进制方式传送的话，2个字节就够了，而用ascii码的话，需要5个字节，在需要大量数据传输的时候就比较浪费有限的带宽了。而16进制数据的缺点呢，就是可读性不强，不像Ascii码那样，直接就能读出数据了。 16进制数据传输的原理是这样的，先要确定数据的表示范围，然后是每个数据可用的字节数。比如角度的数据，每个角度的数据范围是±180度，而2个字节16进制数的表示范围是-32767-32768之间，那么我们就把±180的数据映射到±32768之间。假设原理的数据是x，变换以后的数据是y，那么y=x/180*32768。2个字节能表示的最小精度是1/32768*180=0.0055°，这对于角度的精度来说也够用了。下面具体讲解析的方法。在windows下先通过串口调试助手SSCOM3.2看模块的原始数据，打开相应的串口，注意要选择好正确的波特率，并且将模块的显示模式勾选为HEX显示。如图3 所示。 这里我们以只输出四元数数据为例来说明解析方法，由于这里我设置为只输出四元数数据，所以只有55 59开头的数据，例如55 59 F6 7A 94 00 9F 00 8B 23 FF。如果能看到这种以55 51, 55 52 或者55 53一直到55 59， 55 5A开头的数据，说明串口能够正常接收到数据了。根据使用说明书中的介绍，四元数的数据形式为 那么上述数据中F6 7A就是Q0的数据， 94 00就是Q1的数据，9F 00就是Q2的数据，8B 23就是Q3的数据，FF就是校验和。在Q0的数据中，F6是Q0L,7A是Q0H，那么完整的16进制数据应该是7AF6，这个16进制的数据应该如何表示为十进制的Q0数据就需要我们按照图5中的方法进行解析。 以上是在window中的串口工具读取到的数据，在Linux下我们通过serial功能包读取串口数据，下载地址Github。我们读取到的数据一般保存在一个std::string类型的变量中，比如strRead,这里我们首先将读取到的string数据转换为十六进制的字符串， 1234567891011121314std::string string_to_hex(const std::string&amp; input)&#123; static const char* const lut = "0123456789ABCDEF"; size_t len = input.length(); std::string output; output.reserve(2 * len); for (size_t i = 1; i &lt; len; ++i) &#123; const unsigned char c = input[i]; output.push_back(lut[c &gt;&gt; 4]); output.push_back(lut[c &amp; 15]); &#125; return output;&#125; 123string read;string strResult;strResult = string_to_hex(strRead); 然后我们需要根据一个数据包的报头来判断数据的开始，也就是找到55所在的位置，1data_package_start = strResult.find("55"); 然后我们将这样一组数据读取并保存到一个vector容器中，比如oValueList中123456//将string类型的十六进制数据转换为int类型,然后强制转换为unsigned short类型unsigned short hex2int(const string&amp; hexStr)&#123;char *offset;return strtol(hexStr.c_str(), &amp;offset, 16);&#125; 123456789101112type define unsigned short WORD;vector&lt;WORD&gt; oValueList;string strResultTemp;WORD wordValue;for (int k = 0; k &lt; 8; k++)&#123; strResultTemp = strResult.substr(data_package_start + 4 +2*k, 2); wordValue = hex2int(strResultTemp); oValueList.push_back(wordValue);&#125; 利用string类的函数stbstr()，提取从55 59之后（data_package_start+4）开始的2个字符，直到校验和之前。这样我们就将原来在string类型中以十六进制形式存储的两个字符（比如F6）转存为unsigned short类型（占两个字节），并且push进vector容器中（oValueList[0]）。这样就可以通过vector容器的索引号得到四元数中各个量(Q0,Q1,Q2,Q3)的高低字节（Q0L,Q0H,Q1L,Q1H……）。然后再根据图5显示的四元数的计算方法得到相应的四元数数值。1234double Q0 = (short)(((short)oValueList[1]&lt;&lt;8)|oValueList[0])/32768.0;double Q1 = (short)(((short)oValueList[3]&lt;&lt;8)|oValueList[2])/32768.0;double Q2 = (short)(((short)oValueList[5]&lt;&lt;8)|oValueList[4])/32768.0;double Q3 = (short)(((short)oValueList[7]&lt;&lt;8)|oValueList[6])/32768.0; 发布IMU话题有了四元数数据之后，就可以通过定义一个IMU数据类型，并且将四元数数据赋值即可。 123456789101112ros::Publisher IMU_pub = n.advertise&lt;sensor_msgs::Imu&gt;("imu_data", 20); sensor_msgs::Imu imu_data;imu_data.header.stamp = ros::Time::now();imu_data.header.frame_id = "base_link";imu_data.orientation.x = Q1;imu_data.orientation.y = Q2;imu_data.orientation.z = Q3;imu_data.orientation.w = Q0;imu_pub.publish(imu_data); 这样就成功的发布了imu话题。然后利用imu_tools（下载地址）中的rviz_imu_plugin方法测试imu数据。测试结果如下图：]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ros</tag>
        <tag>imu</tag>
        <tag>JY901</tag>
        <tag>MPU9250</tag>
        <tag>串口解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python notes]]></title>
    <url>%2F2018%2F04%2F16%2Fpython-notes%2F</url>
    <content type="text"><![CDATA[记录学习Python的一些常用语法，此记。 定义函数123456def power(x,n=2): s = 1 while n&gt;0: n = n -1 s = s * x return s 12345def add_end(L=None): if L is None: L = [] L.append('END') return L]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ROS nodelet 介绍]]></title>
    <url>%2F2018%2F04%2F09%2FROS-nodelet-%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[ROS的数据通信在graph结构中以topic,service和param的方式传输数据，数据交互存在一定的延时和阻塞。Nodelet 包就是为改善这一状况设计的， 使得多个算法运行在同一个进程中，并且算法间数据传输无需拷贝就可实现。 详见http://wiki.ros.org/nodelet。 简单的讲就是可以将以前启动的多个node捆绑在一起manager，使得同一个manager里面的topic的数据传输更快，数据通讯中roscpp采用boost shared pointer方式进行publish调用，实现zero copy。Nodelet是借助pluginlib来实现插件动态加载的，文章pluginlib特别通俗易懂的说明了pluginlib的工作原理，在理解pluginlib的基础上看nodelet会更容易。 说明nodelet的工作原理类似于pluginlib，可以参考上边所说的博客中的原理图。 实现一个nodelet插件类nodelet的实现因为借助了pluginlib的插件动态加载，因此nodelet的实现遵循pluginlib的使用规则，主要步骤如下： 创建基类，定义统一的接口。如果是基于现有的基类，则不需要这个步骤 创建nodelet插件类，继承基类，实现统一的接口 注册nodelet插件类 编译生成插件的动态链接库 将nodelet加入ROS系统 接下来，我们就根据这几个步骤来实现一个简单的nodelet功能，在开始之前需要建立一个example_pkg的功能包。 1catkin_create_pkg example_pkg 完整的功能包代码可以在github上下载。 创建基类其中基类nodelet是现有的，所以我们不需要创建基类，只需要继承nodelet基类即可。 创建nodelet插件类并注册插件类接下来我们来创建MyNodeletClass类(MyNodeletClass.h)定义，放置于目录example_pkg/include/example_pkg/下。 123456789101112#include &lt;nodelet/nodelet.h&gt;namespace example_pkg&#123; class MyNodeletClass : public nodelet::Nodelet &#123; public: virtual void onInit(); //要求构造函数不能带有参数，所以调用OnInit来完成需要初始化的工作 &#125;;&#125; 创建MyNodeletClass类实现(MyNodeletClass.cpp)，放置于目录example_pkg/src/下。 123456789101112131415161718// this should really be in the implementation (.cpp file)#include &lt;ros/ros.h&gt;#include &lt;pluginlib/class_list_macros.h&gt;#include &lt;example_pkg/MyNodeletClass.h&gt;namespace example_pkg&#123; void MyNodeletClass::onInit() &#123; NODELET_DEBUG("Initializing nodelet..."); ROS_INFO("Nodelet is Ok for test!!"); &#125;&#125;// 注册插件类PLUGINLIB_DECLARE_CLASS(example_pkg, MyNodeletClass, example_pkg::MyNodeletClass, nodelet::Nodelet) 创建插件类的描述符(nodelet_plugins.xml)，放置于目录example_pkg/plugins/下。1234567&lt;library path="lib/libexample_pkg"&gt; &lt;class name="example_pkg/MyNodeletClass" type="example_pkg::MyNodeletClass" base_class_type="nodelet::Nodelet"&gt; &lt;description&gt; This is my nodelet. &lt;/description&gt; &lt;/class&gt;&lt;/library&gt; 可以看到，这个xml文件主要描述了nodelet的动态库路径，实现类，基类，描述等信息。 编译插件的动态连接库并将插件加入ROS系统为了编译插件的功能包，需要修改CMakeLists.txt文件，修改一下内容，将插件编译为动态连接库。 1234567891011121314151617181920212223242526272829303132333435363738cmake_minimum_required(VERSION 2.8.3)project(example_pkg)## Find catkin macros and libraries## if COMPONENTS list like find_package(catkin REQUIRED COMPONENTS xyz)## is used, also find other catkin packagesfind_package(catkin REQUIRED COMPONENTS nodelet roscpp)find_package(Boost REQUIRED)catkin_package( INCLUDE_DIRS include LIBRARIES $&#123;PROJECT_NAME&#125; CATKIN_DEPENDS nodelet roscpp)############# Build ############### Specify additional locations of header files## Your package locations should be listed before other locationsinclude_directories( include $&#123;catkin_INCLUDE_DIRS&#125; $&#123;Boost_INCLUDE_DIRS&#125;)## Declare a C++ libraryadd_library($&#123;PROJECT_NAME&#125; src/MyNodeletClass.cpp)add_dependencies($&#123;PROJECT_NAME&#125; $&#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; $&#123;catkin_EXPORTED_TARGETS&#125;)target_link_libraries($&#123;PROJECT_NAME&#125; $&#123;catkin_LIBRARIES&#125;) 对package.xml文件进行修改，添加构建和运行依赖项(nodelet和roscpp)。 1234567891011121314&lt;buildtool_depend&gt;catkin&lt;/buildtool_depend&gt;&lt;build_depend&gt;nodelet&lt;/build_depend&gt;&lt;build_depend&gt;roscpp&lt;/build_depend&gt;&lt;exec_depend&gt;nodelet&lt;/exec_depend&gt;&lt;exec_depend&gt;roscpp&lt;/exec_depend&gt;&lt;!-- The export tag contains other, unspecified, tags --&gt;&lt;export&gt; &lt;!-- Other tools can request additional information be placed here --&gt; &lt;nodelet plugin="$&#123;prefix&#125;/plugins/nodelet_plugins.xml" /&gt;&lt;/export&gt; 然后我们可以通过下面的命令来查看该功能包是否编译为nodelet的插件： 1rospack plugins --attrib=plugin nodelet 如果没有问题，会出现一系列nodelet的插件路径，其中应该有上边添加的插件的路径，我的插件路径为： 12345.../opt/ros/kinetic/share/pcl_ros/pcl_nodelets.xml/home/username/catkin_turtlebot/src/example_pkg/plugins/nodelet_plugins.xml #创建的插件路径/opt/ros/kinetic/share/image_publisher/nodelet_plugins.xml... 插件的路径比较多，没有全列出来。 编写启动文件(mynodelet.launch):123456&lt;launch&gt; &lt;node pkg="nodelet" type="nodelet" name="standalone_nodelet" args="manager" output="screen"/&gt; &lt;node pkg="nodelet" type="nodelet" name="MyNodeletClass" args="load example_pkg/MyNodeletClass standalone_nodelet" output="screen"&gt; &lt;/node&gt; &lt;/launch&gt; 编译并测试根目录下编译后，运行launch文件，如果没有问题，可以看到如下结果： 1234567891011121314151617181920212223242526272829username@username-HP-ProBook-440-G3:~/catkin_turtlebot$ roslaunch example_pkg mynodelet.launch ... logging to /home/username/.ros/log/7e42af3c-3b9c-11e8-8278-a86bad0ea915/roslaunch-username-HP-ProBook-440-G3-13823.logChecking log directory for disk usage. This may take awhile.Press Ctrl-C to interruptDone checking log file disk usage. Usage is &lt;1GB.started roslaunch server http://username-HP-ProBook-440-G3:35479/SUMMARY========PARAMETERS * /rosdistro: kinetic * /rosversion: 1.12.13NODES / MyNodeletClass (nodelet/nodelet) standalone_nodelet (nodelet/nodelet)ROS_MASTER_URI=http://localhost:11311process[standalone_nodelet-1]: started with pid [13840]process[MyNodeletClass-2]: started with pid [13841][ INFO] [1523264216.026517404]: Loading nodelet /MyNodeletClass of type example_pkg/MyNodeletClass to manager standalone_nodelet with the following remappings:[ INFO] [1523264216.027989431]: waitForService: Service [/standalone_nodelet/load_nodelet] has not been advertised, waiting...[ INFO] [1523264216.071444856]: Initializing nodelet with 4 worker threads.[ INFO] [1523264216.090658134]: waitForService: Service [/standalone_nodelet/load_nodelet] is now available.[ INFO] [1523264216.092255988]: Nodelet is Ok for test!! 成功后会显示Nodelet is Ok for test!!这样，我们就完成了nodelet插件的实现和调用。]]></content>
      <categories>
        <category>ROS</category>
      </categories>
      <tags>
        <tag>ros</tag>
        <tag>nodelet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正交矩阵的凯莱公式]]></title>
    <url>%2F2018%2F03%2F30%2F%E6%AD%A3%E4%BA%A4%E7%9F%A9%E9%98%B5%E7%9A%84%E5%87%AF%E8%8E%B1%E5%85%AC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[本文主要说明一个线性代数的主要结论-正交矩阵的凯莱公式：对于任何正交矩阵 $R$, 存在一个反对称矩阵 $S$, 满足 $R=(I_3-S)^{-1}(I_3+S)$ ，此记！ 对于原点 $O$ 的一个旋转表示为：\begin{equation}P’=AP\end{equation}其中， $A$ 是一个正交矩阵。因为旋转后的向量长度不发生变化，所以 $({OP})^2=({OP’})^2$ ，并且$$P’\cdot P’-P\cdot P=0$$或者表示为：\begin{equation}(P’-P)\cdot (P’+P)=0\end{equation}其中， $P$ 是任意向量。因此可以得到 $f=P’-P$ 和 $g=P’+P$ 是正交向量。将 $f$，$g$ 和 $P$ 以列向量的形式表示，得到\begin{equation}f=(A-I)P, g=(A+I)P, f\cdot g=0\end{equation}排除 $-1$ 是矩阵 $A$ 的特征值的特例， $A+I$ 就是一个非奇异矩阵，并且\begin{equation}P=(A+I)^{-1}g\end{equation}那么，$$f=(A-I)(A+I)^{-1}g.$$假设\begin{equation}(A-I)(A+I)^{-1}=B，\star\end{equation}那么，\begin{equation}f=Bg\end{equation}假设 $B=[b_{ik}]$ ， $g_i$ 是向量 $g$ 的元素。那么，对于任意的向量 $g$ ， $f\cdot g=0$ 可以改写为：$$\sum_{i,k}(b_{ik}+b_{ki})g_ig_k=0$$那么就可以得到：对于所有的 $i,k$ ， $b_{ik}+b_{ki}=0$ 。因此矩阵$B$是反对称矩阵(skew matrix)。根据公式 $\star$ 可得：$$A-I=B(A+I)$$或者\begin{equation}(I-B)A=I+B\end{equation} 我们知道，如果矩阵$B$是一个实反对称矩阵，那么 $|B|\geq 0$ 。因此， $|B+\lambda I|$ 是关于 $\lambda$ 的带非负系数的多项式，并且除了取 $\lambda=0$ 外多项式的值不为0。也就说 $|B-I|\neq 0$ 。 可以得到结论：对于任意的 $-1$ 不是它的特征值的正交矩阵，正交矩阵可以写为：\begin{equation}A=(I-B)^{-1}(I+B)\end{equation}其中， $B$ 是反对称矩阵，以上公式成为称为凯莱公式。 参考文献： [1]Bottema O, Roth B. Theoretical Kinematics[M]. North-holland Publishing, 1979，pp: 9-10.]]></content>
      <categories>
        <category>Robotics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[等效轴角坐标系表示法]]></title>
    <url>%2F2018%2F03%2F30%2F%E7%AD%89%E6%95%88%E8%BD%B4%E8%A7%92%E5%9D%90%E6%A0%87%E7%B3%BB%E8%A1%A8%E7%A4%BA%E6%B3%95%2F</url>
    <content type="text"><![CDATA[本文主要讲述等效轴角坐标系表示法的导出过程，其中涉及到罗德里格斯公式（Rodrigues’ rotation formula）的推导，此记。 首先将坐标系 $B$ 和一个已知参考坐标系 $A$ 重合。将 $B$ 绕矢量 $^A\hat{K}$ 按右手定则旋转 $\theta$ 角度。等效旋转矩阵的表示形式推导： 目标：将向量 $v=(x,y,z)$ 绕一般方向（而不是主轴方向） $\hat{r}$ （假设 $\hat{r}$ 是单位向量，如果不是，先进行单位化）旋转 $\theta$ 角度，如图1所示。 首先，将向量 $v$ 分解为两部分：平行于 $\hat{r}$ 的 $v_{||}$ 和垂直于 $\hat{r}$ 的 $v_{\bot}$，并且很容易可以得到: $$v_{||}=(v\cdot \hat{r})\hat{r}$$ $$v=v_{||}+v_{\bot}$$ $$v_{\bot}=v-v_{||}$$ $$v_{\bot}=v-(v\cdot \hat{r})\hat{r}$$ 假设，$T$ 是我们所要研究的旋转，我们需要计算 $T(v)$： \begin{align}T(v) &amp; =T(v_{||}+v_{\bot})\\&amp; = T(v_{||})+T(v_{\bot})\end{align} 因为 $v_{||}$ 平行于旋转轴 $\hat{r}$ ，所以 $$T(v_{||})=v_{||}$$ 可以得到： $$T(v)=v_{||}+T(v_{\bot})$$ 其中， $T(v_{\bot})$ 是唯一需要求解的量。所以我们建立旋转平面上的两个基向量(如下图)，把 $v_{\bot}$ 作为第一个基向量，第二个基向量用 \begin{align}w &amp; =\hat{r}\times v_{\bot}\\ &amp; = \hat{r}\times v\end{align} 根据图2，我们可以得到： \begin{align}T(v_{\bot}) &amp; = v_{\bot}cos\theta+ w sin\theta\\&amp;= v_{\bot}cos\theta+(\hat{r}\times v)sin\theta\end{align} 因此， \begin{align}T(v) &amp; =v_{||}+T(v_{\bot})\\&amp;=(v\cdot \hat{r})\hat{r}+ v_{\bot}cos\theta+ (\hat{r}\times v)sin\theta\\&amp;=(v\cdot \hat{r})\hat{r}+ [v-(v\cdot \hat{r})\hat{r}]cos\theta+(\hat{r}\times v)sin\theta\\&amp;=(v\cdot \hat{r})\hat{r}+ vcos\theta- (v\cdot \hat{r})\hat{r}cos\theta+ (\hat{r}\times v)sin\theta\\&amp;=(1-cos \theta)(v\cdot \hat{r})\hat{r}+ v cos\theta+ (\hat{r}\times v)sin\theta\end{align} 得到的该式为Rodrigues公式： $$T(v)=(1-cos \theta)(v\cdot \hat{r})\hat{r}+ v cos\theta+ (\hat{r}\times v)sin\theta$$ 至此，经过变换之后的向量形式已经表示出来了。可以分别通过三个基向量来求得等效旋转矩阵的一般形式： $$p=\begin{vmatrix}1 &amp;0 &amp;0\end{vmatrix}^T $$ 将向量 $p$ 绕轴 $\hat{r}=[k_x,k_y,k_z]$ 旋转(这里为了和参考书形式相同，采用 $k$ 表示)之后的形式表示为， \begin{align}p’ &amp; =(1-cos \theta)(p\cdot \hat{r})\hat{r}+ pcos\theta+(\hat{r}\times p)sin\theta\\&amp;=(1-cos\theta)\left[\left(\begin{matrix}1\\0\\0\end{matrix}\right)\cdot \left(\begin{matrix}k_x\\k_y\\k_z\end{matrix}\right)\right]\left(\begin{matrix}k_x\\k_y\\k_z\end{matrix}\right)+\left(\begin{matrix}1\\0\\0\end{matrix}\right)cos\theta + \left[\left(\begin{matrix}k_x\\k_y\\k_z\end{matrix}\right)\times \left(\begin{matrix}1\\0\\0\end{matrix}\right)\right]sin\theta\\&amp;=\left[\begin{matrix}k_x^2(1-cos\theta)+cos\theta\\k_xk_y(1-cos\theta)+k_zsin\theta\\k_xk_z(1-cos\theta)-k_ysin\theta\end{matrix}\right]\end{align} 类似的，可以将 $q=\begin{vmatrix}0 &amp;1 &amp;0\end{vmatrix}^T$，$r=\begin{vmatrix}0 &amp;0 &amp;1\end{vmatrix}^T$ 经过旋转之后的形式表示为： $$q’=\left[\begin{matrix}k_xk_y(1-cos\theta)-k_z sin\theta\\k_y^2(1-cos\theta)+cos\theta\\k_yk_z(1-cos\theta)+k_xsin\theta\end{matrix}\right]$$ $$r’=\left[\begin{matrix}k_xk_z(1-cos\theta)+k_y sin\theta\\k_yk_z(1-cos\theta)-k_xsin\theta\\k_z^2(1-cos\theta)+cos\theta\end{matrix}\right]$$ 最后，可以得到等效旋转阵的形式： $$R_r(\theta)=\left[\begin{matrix}k_x^2v\theta+c\theta&amp;k_xk_yv\theta-k_zs\theta&amp;k_xk_zv\theta+k_ys\theta\\k_xk_yv\theta+k_zs\theta&amp;k_y^2v\theta+c\theta&amp;k_yk_zv\theta-k_xs\theta\\k_xk_zv\theta-k_ys\theta&amp;k_yk_zv\theta+k_xs\theta&amp;k_z^2v\theta+c\theta\end{matrix}\right]$$ 其中， $c\theta=cos\theta$ , $s\theta=sin\theta$ , $v\theta=1-cos\theta$ ，$\theta$ 是由右手定则确定的，即大拇指指向 $\hat{r}$ 的正方向。]]></content>
      <categories>
        <category>Robotics</category>
      </categories>
      <tags>
        <tag>Rodrigues</tag>
        <tag>rotation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F03%2F30%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server -p 4111 More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment write the latex form1the equation $$x=\sum_&#123;i=1&#125;^nx_i$$ is bla... $$\sum_{i=1}^n$$ insert figure1&#123;% img /等效轴角坐标系表示法/等效轴角坐标系表示法1.jpg 400 268 图1 旋转立体示意图 %&#125; 列表123* 列表1* 列表2* 列表3 1231 列表12 列表25 列表3]]></content>
      <categories>
        <category>Testing</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Test]]></title>
    <url>%2F2018%2F03%2F30%2Ftest-new-post%2F</url>
    <content type="text"><![CDATA[Testing for new post]]></content>
      <categories>
        <category>Testing</category>
      </categories>
      <tags>
        <tag>testing</tag>
        <tag>another tag</tag>
      </tags>
  </entry>
</search>
